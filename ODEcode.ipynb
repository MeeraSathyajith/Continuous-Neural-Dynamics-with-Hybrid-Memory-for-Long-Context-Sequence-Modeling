{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0f55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Meera\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading encoder and extracting PDF text...\n",
      "Reasoning over 250 document steps...\n",
      "\n",
      "========================================\n",
      "HYBRID MODEL ANALYSIS COMPLETE\n",
      "Final Understanding Score: 80.3733\n",
      "Total Sentences Processed: 250\n",
      "Significant Facts Stored in Memory: 249\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# --- 1. CONTINUOUS-TIME REASONING (Neural ODE) ---\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, h):\n",
    "        return self.net(h)\n",
    "\n",
    "\n",
    "# --- 2. HYBRID MODEL ---\n",
    "class HybridNeuralODE(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(HybridNeuralODE, self).__init__()\n",
    "        self.ode_func = ODEFunc(hidden_dim)\n",
    "\n",
    "        # External memory bank (stores important facts)\n",
    "        self.memory_bank = []\n",
    "\n",
    "        self.surprise_threshold = 0.35\n",
    "        self.decoder = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x_sequence):\n",
    "        # Initial hidden state\n",
    "        h = x_sequence[0].unsqueeze(0)\n",
    "\n",
    "        integration_time = torch.linspace(0, 1, 2)\n",
    "\n",
    "        for i in range(1, len(x_sequence)):\n",
    "            # A. Continuous reasoning\n",
    "            h = odeint(self.ode_func, h, integration_time)[-1]\n",
    "\n",
    "            # B. Surprise detection\n",
    "            surprise_score = torch.dist(h, x_sequence[i])\n",
    "\n",
    "            if surprise_score > self.surprise_threshold:\n",
    "                self.memory_bank.append(\n",
    "                    x_sequence[i].detach().clone()\n",
    "                )\n",
    "\n",
    "            # C. Memory retrieval\n",
    "            if len(self.memory_bank) > 0:\n",
    "                memory_info = torch.mean(\n",
    "                    torch.stack(self.memory_bank), dim=0\n",
    "                )\n",
    "                h = h + 0.05 * memory_info\n",
    "\n",
    "        # Final decoding\n",
    "        return self.decoder(h)\n",
    "\n",
    "\n",
    "# --- 3. EXECUTION PIPELINE ---\n",
    "def run_project(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(\"Loading encoder and extracting PDF text...\")\n",
    "    encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    doc = fitz.open(file_path)\n",
    "    sentences = [page.get_text().replace(\"\\n\", \" \") for page in doc]\n",
    "\n",
    "    # Encode text\n",
    "    input_vectors = encoder.encode(\n",
    "        sentences, convert_to_tensor=True\n",
    "    )\n",
    "\n",
    "    # convert inference tensors to normal tensors\n",
    "    input_vectors = input_vectors.clone().detach()\n",
    "\n",
    "    model = HybridNeuralODE(hidden_dim=input_vectors.shape[1])\n",
    "\n",
    "    print(f\"Reasoning over {len(sentences)} document steps...\")\n",
    "\n",
    "    # No gradients needed (inference-only)\n",
    "    with torch.no_grad():\n",
    "        result = model(input_vectors)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"HYBRID MODEL ANALYSIS COMPLETE\")\n",
    "    print(f\"Final Understanding Score: {result.item():.4f}\")\n",
    "    print(f\"Total Sentences Processed: {len(sentences)}\")\n",
    "    print(f\"Significant Facts Stored in Memory: {len(model.memory_bank)}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FILE_NAME = \"HarryPotter.pdf\"  \n",
    "    run_project(FILE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
